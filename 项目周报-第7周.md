# 项目周报

日期：2025-05-25

项目实践题目：文本的匹配与推荐

## 实践内容

### 文献阅读
在Gao 2023文章中，它的related work部分主要讲了以下内容：
1.自监督学习（Self-Supervised Learning）：
BERT 等掩码语言模型展现了强大的文本表示能力。
百亿参数规模的大型语言模型（LLMs）在少样本和零样本任务中表现出色（如 GPT-3）。
对比学习（Contrastive Learning）方法（如 Contriever）通过无监督方式学习文本块的向量表示，无需标注数据即可捕捉文本相似性。
2.指令遵循模型（Instruction-Following Models）：
经过指令微调的 LLMs（如 InstructGPT）能够通过自然语言指令泛化到新任务，无需显式训练。
相关工作包括基于人类反馈的强化学习（RLHF）提升指令遵循能力（如 Ouyang et al. 2022）。
对比同期研究（如 Asai et al. 2022），HyDE 的独特性在于直接使用无监督编码器，无需任务特定微调
3.密集检索（Dense Retrieval）：
基于预训练 Transformer 的密集检索方法（如 DPR、ANCE）通过语义向量相似性实现高效检索。
改进方向包括负采样（Negative Mining）、知识蒸馏（Distillation）、检索导向的预训练（如 RetroMAE）和大模型扩展（如 GTR-XL）。
高效的向量搜索技术（如 GPU 加速的 MIPS）支撑了大规模应用。
4.零样本密集检索（Zero-Shot Dense Retrieval）：
BEIR 基准测试推动了零样本检索的研究，但现有方法依赖大规模标注数据（如 MS MARCO），难以推广到新兴任务。
Izacard et al. (2021) 指出实际场景中标注数据的稀缺性，与本文的零假设（无标注、无领域适应）一致。
5.自动标注（Automatic Labeling）：
通过生成模型（如 LLMs）自动生成问题和伪标签，替代人工标注（如 Wang et al. 2022 的 GPL 方法）。
大规模生成模型（如百亿参数的 Cohere）可进一步提升自动标注质量（Dai et al. 2023）。
6.生成式检索（Generative Retrieval）：
生成式检索直接生成文档标识符（如 Bevilacqua et al. 2022），但需特殊训练和索引结构。
HyDE 与生成式检索的关键区别：通过生成假设文档作为中间表示，并利用标准 MIPS 索引，无需训练数据。

Related Work 部分通过梳理自监督学习、指令遵循模型、密集检索技术、零样本挑战、自动标注和生成式检索，明确了现有方法的局限：
零样本检索依赖大规模标注数据（如 MS MARCO），缺乏灵活性；
生成式检索需复杂训练和索引，难以通用化

支线任务是搜索论文参考文献并阅读其related work部分，找到Natural Questions: A Benchmark for Question Answering Research一文其related work主要讲了
作者通过对比主流 QA 数据集的局限性（如评估指标缺陷、任务设计脱离实际、标注主观性等），凸显了 NQ 在以下方面的创新性：
任务设计：平衡复杂推理需求与实用性。
评估方法：通过标注变异性计算可靠的人类性能上限。
数据质量：基于真实用户行为，避免人工构造偏差。
最终，NQ 被定位为更贴近真实场景、更具挑战性的 NLU 评测基准。

### 下周规划

下周继续阅读一下论文及其参考文献，参考文献可以有选择的去读，一篇论文的参考文献很多，要挑一部分相关性较高的去读，提高效率。