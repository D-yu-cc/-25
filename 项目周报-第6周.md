# 项目周报

日期：2025-05-18

项目实践题目：文本的匹配与推荐

## 实践内容

### 文献阅读

本周开始阅读Gao 2023的文章从摘要可知本文把主要讲了提出Hypothetical Document Embeddings(HyDE)方法，用于零样本密集检索。
核心思想：
使用指令遵循的语言模型（如InstructGPT）根据查询生成“假设文档”（可能包含虚构内容）。
通过无监督对比编码器（如Contriever）将假设文档编码为向量，基于向量相似度从真实文档库中检索相关文档。
实验表明，HyDE在多个任务（如网页搜索、问答、事实核查）和语言（如斯瓦希里语、韩语、日语、孟加拉语）中优于无监督基线，并与监督模型性能相当。

HyDE的创新：
分解检索为两步：生成假设文档（NLG任务）和文档相似性计算（NLU任务）。
无需训练，直接使用预训练的生成模型和对比编码器。
实验验证HyDE在11个查询集上的有效性，覆盖多任务和多语言场景。

HyDE的核心思想
分解检索任务
生成假设文档：使用指令遵循的大模型（如InstructGPT）根据查询生成“假设文档”（hypothetical document）。
假设文档可能包含错误或虚构内容，但能捕捉相关性模式（如关键词、逻辑结构）。
对比编码与检索：通过无监督编码器（如Contriever）将假设文档映射到向量空间，基于向量相似度检索真实文档。

关键创新
无需相关性标签：完全依赖生成模型的语义理解能力和编码器的文档相似性建模。
零样本适配：直接应用于新任务或语言，无需额外训练或领域适配。
模块化设计：生成模型与编码器独立，可灵活替换（如用FLAN-T5替换InstructGPT）。

### 其他

看的这部分提出了HyDE方法，通过生成假设文档并利用无监督编码器实现零样本密集检索，无需相关标签，在跨任务和跨语言场景中表现优异。
HyDE巧妙结合生成与对比学习，为无监督检索开辟新路径，但生成模型的可靠性与效率仍需进一步优化。